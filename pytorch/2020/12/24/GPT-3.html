<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>GPT-3 | Priyank AI Blogs</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="GPT-3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Generative Pre-trained Transformer : Next Step towards AGI" />
<meta property="og:description" content="Generative Pre-trained Transformer : Next Step towards AGI" />
<link rel="canonical" href="https://priyank7n.me/pytorch/2020/12/24/GPT-3.html" />
<meta property="og:url" content="https://priyank7n.me/pytorch/2020/12/24/GPT-3.html" />
<meta property="og:site_name" content="Priyank AI Blogs" />
<meta property="og:image" content="https://priyank7n.me/images/gpt.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-24T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://priyank7n.me/pytorch/2020/12/24/GPT-3.html","@type":"BlogPosting","headline":"GPT-3","dateModified":"2020-12-24T00:00:00-06:00","datePublished":"2020-12-24T00:00:00-06:00","image":"https://priyank7n.me/images/gpt.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://priyank7n.me/pytorch/2020/12/24/GPT-3.html"},"description":"Generative Pre-trained Transformer : Next Step towards AGI","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://priyank7n.me/feed.xml" title="Priyank AI Blogs" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Priyank AI Blogs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">GPT-3</h1><p class="page-description">Generative Pre-trained Transformer : Next Step towards AGI</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-24T00:00:00-06:00" itemprop="datePublished">
        Dec 24, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Pytorch">Pytorch</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#gpt-3">GPT-3</a></li>
<li class="toc-entry toc-h1"><a href="#facts-about-gpt-3">Facts about GPT-3</a></li>
<li class="toc-entry toc-h1"><a href="#gpt-3-training-phase">GPT-3 Training phase</a></li>
<li class="toc-entry toc-h1"><a href="#gpt-3-working--architecture">GPT-3 Working &amp; Architecture</a></li>
<li class="toc-entry toc-h1"><a href="#gpt-3s-potential-applications">GPT-3’s Potential Applications</a></li>
<li class="toc-entry toc-h1"><a href="#gpt-3-limitations">GPT-3 Limitations</a></li>
<li class="toc-entry toc-h1"><a href="#future-scope">Future Scope</a></li>
</ul><h1 id="gpt-3">
<a class="anchor" href="#gpt-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPT-3</h1>

<p><strong>GPT-3 stands for Generative Pre-trained Transformer 3.</strong>
It is a gargantuan artificial Neural Network (NN) around the size of a mouse brain, trained on essentially the whole internet and millions of and GPT-3 is a language model, which means that, using sequence transduction, it can predict the likelihood of an output sequence given an input sequence. This can be used, for instance to predict which word makes the most sense given a text sequence.</p>

<p><img src="/images/media/image1.gif" alt=""></p>

<h1 id="facts-about-gpt-3">
<a class="anchor" href="#facts-about-gpt-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Facts about GPT-3</h1>

<p><img src="/images/media/image2.png" alt=""></p>

<ul>
  <li>
    <p>Trained on 300 Billion words has been trained using also huge datasets, including the <a href="https://commoncrawl.org/">Common Crawl</a> dataset and the <a href="https://en.wikipedia.org/wiki/Main_Page">English-language Wikipedia</a> (<a href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential">spanning some 6 million articles, and making up only 0.6 percent of its training data</a>),</p>
  </li>
  <li>
    <p>GPT-3 uses 175 Billion parameters (Previous model GPT-2 “only” used 1,5 billion parameters.)</p>
  </li>
  <li>
    <p>96 NN Layers (more than human brain has for interactive tasks!)</p>
  </li>
  <li>
    <p>A few $Million$ computing cost for training,but can write a whole book for $1 electricity cost.</p>
  </li>
  <li>
    <p>Top-5 super-computer: 285’000 CPUs + 10’000 GPUs</p>
  </li>
  <li>
    <p>Simpler works better: no encoders and no recurrence</p>
  </li>
  <li>
    <p>GPT-3 is a Generative Pre-Trained Transformer (once only!)</p>
  </li>
  <li>
    <p>Once trained, you prompt it with a (con)text of up to 12288 (sub)words</p>
  </li>
  <li>
    <p>GPT-3 is not fine-tuned (adapted in any way) to different tasks</p>
  </li>
</ul>

<h1 id="gpt-3-training-phase">
<a class="anchor" href="#gpt-3-training-phase" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPT-3 Training phase</h1>

<p><img src="/images/media/image3.png" alt=""></p>

<p>The dataset of 300 billion tokens of text is used to generate training examples for the model. For example, these are three training examples generated from the one sentence at the top.</p>

<p><img src="/images/media/image4.gif" alt=""></p>

<p>The model is presented with an example. We only show it the features and ask it to predict the next word.</p>

<p>The model’s prediction will be wrong. We calculate the error in its prediction and update the model so next time it makes a better prediction. Repeat millions of times</p>

<h1 id="gpt-3-working--architecture">
<a class="anchor" href="#gpt-3-working--architecture" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPT-3 Working &amp; Architecture</h1>

<p><img src="/images/media/image5.gif" alt=""></p>

<p>Let’s follow the purple track. How does a system process the word “robotics” and produce “A”?</p>

<p>High-level steps:</p>

<ol>
  <li>
    <p>Convert the word to <a href="https://jalammar.github.io/illustrated-word2vec/">a vector (list of numbers) representing the word</a></p>
  </li>
  <li>
    <p>Compute prediction</p>
  </li>
  <li>
    <p>Convert resulting vector to word</p>
  </li>
</ol>

<p><img src="/images/media/image6.gif" alt=""></p>

<p>The important calculations of the GPT3 occur inside its stack of 96 transformer decoder layers. This is the “depth” in “deep learning”. Each of these layers has its own 1.8B parameter to make its calculations. That is where the “magic” happens.</p>

<p>Let’s follow the purple track. How does a system process the word “robotics” and produce “A”?</p>

<p>High-level steps:</p>

<ol>
  <li>
    <p>Convert the word to <a href="https://jalammar.github.io/illustrated-word2vec/">a vector (list of numbers) representing the word</a></p>
  </li>
  <li>
    <p>Compute prediction</p>
  </li>
  <li>
    <p>Convert resulting vector to word</p>
  </li>
</ol>

<h1 id="gpt-3s-potential-applications">
<a class="anchor" href="#gpt-3s-potential-applications" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPT-3’s Potential Applications</h1>

<ul>
  <li>
    <p>Writing short fiction, poetry, press releases, jokes, technical manuals, news articles, …(semi) automated journalism</p>
  </li>
  <li>
    <p>Text translation</p>
  </li>
  <li>
    <p>Text Adventure Game creation/generation</p>
  </li>
  <li>
    <p>Text summarization</p>
  </li>
  <li>
    <p>Question answering</p>
  </li>
  <li>
    <p>Convert plain text to and from legal English</p>
  </li>
  <li>
    <p>Produce functional code Mathematical formulas</p>
  </li>
  <li>
    <p>Write poetry and</p>
  </li>
  <li>
    <p>Play Chess and Go, but not well.</p>
  </li>
  <li>
    <p>Do very simple arithmetic</p>
  </li>
  <li>
    <p>customer support chat bot</p>
  </li>
  <li>
    <p>grammar assistance</p>
  </li>
  <li>
    <p>improving search engine responses auto-generated articles (stocks, finance)</p>
  </li>
</ul>

<div class="Toast Toast--warning googoo">
   <span class="Toast-icon"><svg class="octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path></svg></span>
   <span class="Toast-content">Harmful-applications</span>
</div>

<ul>
  <li>
    <p>troll bots derailing online discussions</p>
  </li>
  <li>
    <p>fake news</p>
  </li>
  <li>
    <p>cheat on exams and essay assignments</p>
  </li>
</ul>

<h1 id="gpt-3-limitations">
<a class="anchor" href="#gpt-3-limitations" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPT-3 Limitations</h1>

<ul>
  <li>
    <p>Limited common-sense and causal reasoning compared to SOTA and humans <em>(bias towards knowledge rather than intelligence)</em></p>
  </li>
  <li>
    <p>Limited Natural Language &amp; Logical Inference, e.g. comparing sentences A and B (e.g. is word used the same way in A and B , A paraphrases B, A implies B)</p>
  </li>
  <li>
    <p>Unsuitable for bidirectional tasks, such as Cloze</p>
  </li>
  <li>
    <p><em>(a robot obey orders)</em></p>
  </li>
  <li>
    <p>Only good for prediction tasks, not suitable for problems that require sequential decision-making and real truth grounding <em>(acting and planning ahead)</em></p>
  </li>
  <li>
    <p>Performance is unreliable and unpredictable</p>
  </li>
</ul>

<h1 id="future-scope">
<a class="anchor" href="#future-scope" aria-hidden="true"><span class="octicon octicon-link"></span></a>Future Scope</h1>

<ul>
  <li>
    <p>Larger Models: GPT-3 is still “only” 0.05% of a human brain</p>
  </li>
  <li>
    <p>More data? We nearly reached the limit of available English text</p>
  </li>
  <li>
    <p>Different modalities: most important: vision; speech I/O is solved</p>
  </li>
  <li>
    <p>Other languages: for translation, non-English conversation, culture- specific knowledge</p>
  </li>
  <li>
    <p>More data-efficient training: humans 1000x more efficient</p>
  </li>
  <li>
    <p>Lifelong learning: online, fine-tuning</p>
  </li>
</ul>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="PriyanK7n/fastblogs"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/pytorch/2020/12/24/GPT-3.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>This is a place for Priyank to display his projects and talk about stuff and ideas he&#39;s interested in and looking forward to 2021.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/PriyanK_7n" title="PriyanK_7n"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/PriyanK_7n" title="PriyanK_7n"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
